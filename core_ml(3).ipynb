{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GkNsMTpvPewX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# Print versions to confirm installation\n",
        "print(f'Torch version: {torch.__version__}')\n",
        "print(f'Torchvision version: {torchvision.__version__}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"\\nUsing device: {device}\")"
      ],
      "metadata": {
        "id": "f0iGyHMEkODK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transformations for data normalization\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize to [-1, 1]\n",
        "])\n",
        "\n",
        "# Download and prepare training and test datasets\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=256, shuffle=False, num_workers=2)\n",
        "\n",
        "# Print dataset sizes\n",
        "print(f'Training set size: {len(trainset)}')\n",
        "print(f'Test set size: {len(testset)}')\n"
      ],
      "metadata": {
        "id": "GDCz8DWxQNri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to unnormalize and display images\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5  # Unnormalize from [-1, 1] to [0, 1]\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "# Get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# Show images and corresponding labels\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "print(' '.join(f'{trainset.classes[labels[j]]}' for j in range(4)))\n"
      ],
      "metadata": {
        "id": "r02IAnnzQvpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_symmetric_noise(labels, noise_rate=0.2, num_classes=10):\n",
        "    \"\"\"\n",
        "    Introduce symmetric noise by randomly flipping labels to any other class.\n",
        "\n",
        "    Args:\n",
        "        labels (list or np.array): Original labels.\n",
        "        noise_rate (float): Fraction of labels to flip.\n",
        "        num_classes (int): Total number of classes.\n",
        "\n",
        "    Returns:\n",
        "        np.array: Labels with symmetric noise.\n",
        "    \"\"\"\n",
        "    noisy_labels = np.array(labels)\n",
        "    num_noisy = int(len(labels) * noise_rate)\n",
        "    noisy_indices = np.random.choice(len(labels), num_noisy, replace=False)\n",
        "\n",
        "    for idx in noisy_indices:\n",
        "        original_label = noisy_labels[idx]\n",
        "        noisy_labels[idx] = np.random.choice([i for i in range(num_classes) if i != original_label])\n",
        "\n",
        "    return noisy_labels\n",
        "\n",
        "\n",
        "def add_asymmetric_noise(labels, noise_rate=0.1):\n",
        "    \"\"\"\n",
        "    Introduce asymmetric noise by flipping labels to specific incorrect classes.\n",
        "\n",
        "    Args:\n",
        "        labels (list or np.array): Original labels.\n",
        "        noise_rate (float): Fraction of labels to flip.\n",
        "\n",
        "    Returns:\n",
        "        np.array: Labels with asymmetric noise.\n",
        "    \"\"\"\n",
        "    noisy_labels = np.array(labels)\n",
        "    num_noisy = int(len(labels) * noise_rate)\n",
        "    noisy_indices = np.random.choice(len(labels), num_noisy, replace=False)\n",
        "\n",
        "    # Define asymmetric noise mapping (e.g., class 0 flips to class 1, etc.)\n",
        "    noise_mapping = {\n",
        "        0: 1, 1: 2, 2: 3, 3: 4, 4: 5,\n",
        "        5: 6, 6: 7, 7: 8, 8: 9, 9: 0\n",
        "    }\n",
        "\n",
        "    for idx in noisy_indices:\n",
        "        original_label = noisy_labels[idx]\n",
        "        noisy_labels[idx] = noise_mapping[original_label]\n",
        "\n",
        "    return noisy_labels\n",
        "\n"
      ],
      "metadata": {
        "id": "MczD6-JVShfF"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Example CIFAR-10 labels (0-9 classes)\n",
        "original_labels = np.random.randint(0, 10, size=100)\n",
        "\n",
        "# Apply symmetric noise\n",
        "noisy_labels_symmetric = add_symmetric_noise(original_labels, noise_rate=0.2, num_classes=10)\n",
        "\n",
        "# Apply asymmetric noise\n",
        "noisy_labels_asymmetric = add_asymmetric_noise(original_labels, noise_rate=0.1)\n",
        "\n",
        "# Visualize symmetric noise\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(original_labels, bins=np.arange(11)-0.5, edgecolor='black', color='cyan')\n",
        "plt.title(\"Original Labels Distribution\")\n",
        "plt.xlabel(\"Class\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(noisy_labels_symmetric, bins=np.arange(11)-0.5, edgecolor='black', color='cyan')\n",
        "plt.title(\"Labels After Symmetric Noise\")\n",
        "plt.xlabel(\"Class\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Visualize asymmetric noise\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(original_labels, bins=np.arange(11)-0.5, edgecolor='black', color='cyan')\n",
        "plt.title(\"Original Labels Distribution\")\n",
        "plt.xlabel(\"Class\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(noisy_labels_asymmetric, bins=np.arange(11)-0.5, edgecolor='black', color='cyan')\n",
        "plt.title(\"Labels After Asymmetric Noise\")\n",
        "plt.xlabel(\"Class\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "DJr3TdrJSsXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class CIFAR10_CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Conv Block 1\n",
        "        self.block1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 3, padding=1),  # Output: 32x32x32\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2)  # Output: 16x16x32\n",
        "        )\n",
        "\n",
        "        # Conv Block 2\n",
        "        self.block2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, 3, padding=1),  # Output: 16x16x64\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2)  # Output: 8x8x64\n",
        "        )\n",
        "\n",
        "        # Conv Block 3 (No Pooling)\n",
        "        self.block3 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, 3, padding=1),  # Output: 8x8x128\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # Conv Block 4 (No Pooling)\n",
        "        self.block4 = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, 3, padding=1),  # Output: 8x8x256\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # Classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(256 * 8 * 8, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.block3(x)\n",
        "        x = self.block4(x)\n",
        "        return self.classifier(x)\n",
        "\n",
        "    def to_device(self):\n",
        "        self.to(device)\n",
        "        return self\n",
        "\n",
        "# Test the model\n",
        "if __name__ == \"__main__\":\n",
        "    model = CIFAR10_CNN()\n",
        "    test_input = torch.randn(4, 3, 32, 32)  # Batch of 4 CIFAR-10 images\n",
        "    print(\"Output shape:\", model(test_input).shape)  # Should be (4, 10)\n"
      ],
      "metadata": {
        "id": "eYWYu7lGchjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define the model (assuming CIFAR10_CNN is already defined)\n",
        "model = CIFAR10_CNN()\n",
        "\n",
        "# Define the SGD optimizer with weight decay and momentum\n",
        "optimizer = torch.optim.SGD(\n",
        "    model.parameters(),  # Pass the model's parameters\n",
        "    lr=0.01,             # Learning rate\n",
        "    momentum=0.9,        # Momentum value\n",
        "    weight_decay=1e-4    # Weight decay (L2 regularization)\n",
        ")\n",
        "\n",
        "# Print optimizer details to verify\n",
        "print(optimizer)\n"
      ],
      "metadata": {
        "id": "AUmlUF26dZc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Phase 1: Standard Loss Functions --------------------------------------------------\n",
        "def cross_entropy(outputs, targets):\n",
        "    \"\"\"Standard Cross-Entropy Loss\"\"\"\n",
        "    return F.cross_entropy(outputs, targets)\n",
        "\n",
        "def mean_absolute_error(outputs, targets):\n",
        "    \"\"\"Mean Absolute Error (MAE) between outputs and one-hot targets\"\"\"\n",
        "    one_hot_targets = F.one_hot(targets, num_classes=outputs.size(1)).float()\n",
        "    return torch.mean(torch.abs(outputs - one_hot_targets))\n",
        "\n",
        "def reversed_cross_entropy(outputs, targets):\n",
        "    \"\"\"Reverse Cross-Entropy (RCE)\"\"\"\n",
        "    softmax_outputs = F.softmax(outputs, dim=1)\n",
        "    one_hot_targets = F.one_hot(targets, num_classes=outputs.size(1)).float()\n",
        "    return -torch.mean(torch.sum((1 - one_hot_targets) * torch.log(softmax_outputs + 1e-8), dim=1))\n",
        "\n",
        "def focal_loss(outputs, targets, gamma=2):\n",
        "    \"\"\"Focal Loss (Handles class imbalance)\"\"\"\n",
        "    ce_loss = F.cross_entropy(outputs, targets, reduction='none')\n",
        "    pt = torch.exp(-ce_loss)\n",
        "    return torch.mean((1 - pt) ** gamma * ce_loss)\n",
        "\n",
        "# Test the loss functions -----------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    # Test case: 2 samples, 3 classes\n",
        "    logits = torch.tensor([[2.0, 1.0, 0.1], [0.1, 2.0, 1.0]])\n",
        "    labels = torch.tensor([0, 1])  # Class indices\n",
        "\n",
        "    print(\"CE:\", cross_entropy(logits, labels).item())\n",
        "    print(\"MAE:\", mean_absolute_error(logits, labels).item())\n",
        "    print(\"RCE:\", reversed_cross_entropy(logits, labels).item())\n",
        "    print(\"Focal:\", focal_loss(logits, labels).item())\n"
      ],
      "metadata": {
        "id": "wHsSJWc0dfhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Phase 2: Optimized Normalized Loss Functions ----------------------------------------\n",
        "def normalized_cross_entropy(outputs, targets):\n",
        "    \"\"\"NCE = log p(y|x) / log(prod_k p(k|x))\"\"\"\n",
        "    probs = F.softmax(outputs, dim=1)\n",
        "    log_probs = torch.log(probs + 1e-8)  # Numerical stability\n",
        "    numerator = log_probs[torch.arange(len(targets)), targets]\n",
        "    denominator = torch.sum(log_probs, dim=1)\n",
        "    return torch.mean(numerator / denominator)\n",
        "\n",
        "def normalized_mean_absolute_error(outputs, targets):\n",
        "    \"\"\"NMAE = MAE * 1/(2*(K-1))\"\"\"\n",
        "    K = outputs.size(1)\n",
        "    return mean_absolute_error(outputs, targets) * (1/(2*(K-1)))\n",
        "\n",
        "def normalized_reversed_cross_entropy(outputs, targets):\n",
        "    \"\"\"NRCE = RCE * 1/(A*(K-1)) (A=1 from paper proofs)\"\"\"\n",
        "    K = outputs.size(1)\n",
        "    return reversed_cross_entropy(outputs, targets) * (1/(1*(K-1)))\n",
        "\n",
        "def normalized_focal_loss(outputs, targets, gamma=2):\n",
        "    \"\"\"NFL = log[(1-p_y)^γ p_y] / log[prod_k (1-p_k)^γ p_k]\"\"\"\n",
        "    probs = F.softmax(outputs, dim=1)\n",
        "    log_terms = torch.log((1 - probs)**gamma * probs + 1e-8)\n",
        "    numerator = log_terms[torch.arange(len(targets)), targets]\n",
        "    denominator = torch.sum(log_terms, dim=1)\n",
        "    return torch.mean(numerator / denominator)\n",
        "\n"
      ],
      "metadata": {
        "id": "J-5xECKEdf41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class APLLoss:\n",
        "    def __init__(self, active_loss, passive_loss, alpha=1.0, beta=1.0):\n",
        "        \"\"\"\n",
        "        Implements the APL framework from the paper:\n",
        "        L_APL = α * L_Active + β * L_Passive\n",
        "\n",
        "        Args:\n",
        "            active_loss: One of [NCE, NFL] (normalized active losses)\n",
        "            passive_loss: One of [NMAE, NRCE] (normalized passive losses)\n",
        "            alpha: Weight for active loss term\n",
        "            beta: Weight for passive loss term\n",
        "        \"\"\"\n",
        "        self.active_loss = active_loss\n",
        "        self.passive_loss = passive_loss\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "\n",
        "    def __call__(self, outputs, targets):\n",
        "        active_term = self.active_loss(outputs, targets)\n",
        "        passive_term = self.passive_loss(outputs, targets)\n",
        "        return self.alpha * active_term + self.beta * passive_term\n",
        "\n",
        "# Example usage with paper's first combination: αNCE + βMAE\n",
        "apl_nce_mae = APLLoss(\n",
        "    active_loss=normalized_cross_entropy,\n",
        "    passive_loss=normalized_mean_absolute_error,\n",
        "    alpha=1.0,\n",
        "    beta=1.0\n",
        ")\n"
      ],
      "metadata": {
        "id": "3uAq6hlJv9OU"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test case --------------------------------------------------------\n",
        "logits = torch.tensor([\n",
        "    [3.0, 1.0, 0.1],  # Class 0 dominant\n",
        "    [0.1, 3.0, 0.1],  # Class 1 dominant\n",
        "    [0.1, 0.1, 3.0]   # Class 2 dominant\n",
        "])\n",
        "labels = torch.tensor([0, 1, 2])  # All correct labels\n",
        "\n",
        "# Calculate individual components for verification\n",
        "nce = normalized_cross_entropy(logits, labels)  # ~0.333\n",
        "nmae = normalized_mean_absolute_error(logits, labels)  # ~0.000\n",
        "\n",
        "# Calculate APL loss\n",
        "apl_loss = apl_nce_mae(logits, labels)\n",
        "\n"
      ],
      "metadata": {
        "id": "8G3RfY-zx2X-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from copy import deepcopy\n",
        "\n",
        "# Configuration\n",
        "NUM_EPOCHS = 50\n",
        "BATCH_SIZE = 128\n",
        "NOISE_RATES = {'symmetric': [0.2, 0.4, 0.6, 0.8],\n",
        "               'asymmetric': [0.1, 0.2, 0.3, 0.4]}\n",
        "LOSS_FUNCTIONS = {\n",
        "    'CE': cross_entropy,\n",
        "    'FL': lambda o, t: focal_loss(o, t, gamma=2),\n",
        "    'NCE': normalized_cross_entropy,\n",
        "    'NFL': lambda o, t: normalized_focal_loss(o, t, gamma=2),\n",
        "    #'APL(NCE+MAE)': APLLoss(normalized_cross_entropy, normalized_mean_absolute_error),\n",
        "    #'APL(NFL+RCE)': APLLoss(normalized_focal_loss, normalized_reversed_cross_entropy)\n",
        "}\n",
        "\n",
        "def run_experiments():\n",
        "    # Load clean dataset once\n",
        "    original_trainset = torchvision.datasets.CIFAR10(\n",
        "        root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "    # Store final results across all experiments\n",
        "    final_results = {ntype: {} for ntype in NOISE_RATES.keys()}\n",
        "\n",
        "    for noise_type, rates in NOISE_RATES.items():\n",
        "        for eta in rates:\n",
        "            print(f\"\\n{'-'*40}\\nTraining with {noise_type} noise η={eta}\\n{'-'*40}\")\n",
        "\n",
        "            # Create noisy dataset copy\n",
        "            noisy_trainset = deepcopy(original_trainset)\n",
        "            original_targets = noisy_trainset.targets.copy()\n",
        "\n",
        "            # Apply noise\n",
        "            if noise_type == 'symmetric':\n",
        "                noisy_targets = add_symmetric_noise(original_targets, eta)\n",
        "            else:\n",
        "                noisy_targets = add_asymmetric_noise(original_targets, eta)\n",
        "\n",
        "            noisy_trainset.targets = noisy_targets\n",
        "            train_loader = DataLoader(noisy_trainset, batch_size=BATCH_SIZE,\n",
        "                                    shuffle=True, num_workers=2, pin_memory=True)\n",
        "\n",
        "            # Train all loss functions simultaneously\n",
        "            results = train_single_experiment(train_loader, eta, noise_type)\n",
        "            final_results[noise_type][eta] = results\n",
        "\n",
        "            # Cleanup\n",
        "            del noisy_trainset\n",
        "            plot_metrics(results, eta, noise_type)\n",
        "\n",
        "    # Plot final comparison\n",
        "    plot_final_comparison(final_results)\n",
        "    return final_results\n",
        "\n",
        "def train_single_experiment(train_loader, eta, noise_type):\n",
        "    models = {name: CIFAR10_CNN().to_device() for name in LOSS_FUNCTIONS.keys()}\n",
        "    optimizers = {name: torch.optim.SGD(model.parameters(), lr=0.01,\n",
        "                                      momentum=0.9, weight_decay=1e-4)\n",
        "                for name, model in models.items()}\n",
        "\n",
        "    metrics = {name: {'train_loss': [], 'train_acc': [],\n",
        "                     'test_acc': []} for name in LOSS_FUNCTIONS.keys()}\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        # Training phase\n",
        "        for name, model in models.items():\n",
        "            model.train()\n",
        "            epoch_loss = 0.0\n",
        "            correct = 0\n",
        "            total = 0\n",
        "\n",
        "            for inputs, labels in train_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                optimizers[name].zero_grad()\n",
        "                outputs = model(inputs)\n",
        "                loss = LOSS_FUNCTIONS[name](outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizers[name].step()\n",
        "\n",
        "                epoch_loss += loss.item() * inputs.size(0)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "            # Evaluation\n",
        "            train_acc = 100 * correct / total\n",
        "            test_acc = evaluate(models[name], testloader)\n",
        "\n",
        "            # Store metrics\n",
        "            metrics[name]['train_loss'].append(epoch_loss / len(train_loader.dataset))\n",
        "            metrics[name]['train_acc'].append(train_acc)\n",
        "            metrics[name]['test_acc'].append(test_acc)\n",
        "\n",
        "            # Print progress\n",
        "            print(f\"Epoch {epoch+1:02d}/{NUM_EPOCHS} | {name:12} | \"\n",
        "                  f\"Loss: {metrics[name]['train_loss'][-1]:.4f} | \"\n",
        "                  f\"Train Acc: {train_acc:.2f}% | \"\n",
        "                  f\"Test Acc: {test_acc:.2f}%\")\n",
        "\n",
        "    return metrics\n",
        "\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "def plot_metrics(metrics, eta, noise_type):\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    for name, data in metrics.items():\n",
        "        plt.plot(data['train_acc'], label=name)\n",
        "    plt.title(f'Training Accuracy ({noise_type} η={eta})')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    for name, data in metrics.items():\n",
        "        plt.plot(data['test_acc'], label=name)\n",
        "    plt.title(f'Test Accuracy ({noise_type} η={eta})')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'results_{noise_type}_eta{eta}.png')\n",
        "    plt.show()\n",
        "\n",
        "def plot_final_comparison(final_results):\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    for noise_type in NOISE_RATES.keys():\n",
        "        plt.subplot(1, 2, 1 if noise_type == 'symmetric' else 2)\n",
        "        for name in LOSS_FUNCTIONS.keys():\n",
        "            accuracies = [final_results[noise_type][eta][name]['test_acc'][-1]\n",
        "                         for eta in NOISE_RATES[noise_type]]\n",
        "            plt.plot(NOISE_RATES[noise_type], accuracies, marker='o', label=name)\n",
        "\n",
        "        plt.title(f'{noise_type.capitalize()} Noise Comparison')\n",
        "        plt.xlabel('Noise Rate')\n",
        "        plt.ylabel('Final Test Accuracy (%)')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('final_comparison.png')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_symmetric_only(final_results):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    noise_type = 'symmetric'\n",
        "\n",
        "    for name in LOSS_FUNCTIONS.keys():\n",
        "        accuracies = [final_results[noise_type][eta][name]['test_acc'][-1]\n",
        "                    for eta in NOISE_RATES[noise_type]]\n",
        "        plt.plot(NOISE_RATES[noise_type], accuracies, marker='o', label=name)\n",
        "\n",
        "    plt.title('Symmetric Noise Comparison')\n",
        "    plt.xlabel('Noise Rate')\n",
        "    plt.ylabel('Final Test Accuracy (%)')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig('symmetric_comparison.png')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Initialize datasets\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "    testset = torchvision.datasets.CIFAR10(\n",
        "        root='./data', train=False, download=True, transform=transform)\n",
        "    testloader = DataLoader(testset, batch_size=256, shuffle=False,\n",
        "                          num_workers=2, pin_memory=True)\n",
        "\n",
        "    # Run full experiment suite\n",
        "    final_results = run_experiments()\n",
        "    plot_symmetric_only(final_results)\n"
      ],
      "metadata": {
        "id": "BBdtfL9JRqH5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}